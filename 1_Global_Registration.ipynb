{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEhcSUW3GtLn"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torchvision import transforms, models\n",
        "from scipy.signal import correlate2d\n",
        "import math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "import time\n",
        "from psutil import virtual_memory\n",
        "from skimage import io\n",
        "from skimage.metrics import normalized_root_mse as ncc, structural_similarity as ssim\n",
        "from scipy.ndimage.filters import gaussian_gradient_magnitude\n",
        "from sklearn.base import BaseEstimator\n",
        "from scipy.interpolate import griddata\n",
        "from sklearn.cluster import KMeans\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_image(image):\n",
        "    min_val = image.min()\n",
        "    max_val = image.max()\n",
        "    if max_val != min_val:\n",
        "        image = (image - min_val) / (max_val - min_val) * 65535\n",
        "    return image.astype('uint16')"
      ],
      "metadata": {
        "id": "_PlMbOxHGxJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def likelihood(error, sigma):\n",
        "    return np.exp(-error**2 / (2 * sigma**2))\n",
        "\n",
        "class HomographyModel(BaseEstimator):\n",
        "    def fit(self, X, y=None):\n",
        "        src_pts = X[:, :2].reshape(-1, 1, 2)\n",
        "        dst_pts = X[:, 2:].reshape(-1, 1, 2)\n",
        "        self.H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC)\n",
        "        return self\n",
        "\n",
        "    def errors(self, X, y=None):\n",
        "        src_pts = X[:, :2].reshape(-1, 1, 2)\n",
        "        dst_pts = X[:, 2:].reshape(-1, 1, 2)\n",
        "        dst_pts_estimated = cv2.perspectiveTransform(src_pts, self.H)\n",
        "        return np.sqrt(np.sum((dst_pts - dst_pts_estimated)**2, axis=2)).ravel()\n",
        "\n",
        "def mlesac(data, model_class, min_samples, max_iterations, sigma, threshold):\n",
        "    best_model = None\n",
        "    best_likelihood = 0\n",
        "    best_inliers = None\n",
        "\n",
        "    for _ in range(max_iterations):\n",
        "        sample = data[np.random.choice(data.shape[0], min_samples, replace=False)]\n",
        "        model = model_class()\n",
        "        model.fit(sample)\n",
        "        errors = model.errors(data)\n",
        "        inliers = data[errors <= threshold]\n",
        "        outliers = data[errors > threshold]\n",
        "        likelihood_inliers = np.sum(likelihood(errors[errors <= threshold], sigma))\n",
        "        likelihood_outliers = np.sum(likelihood(errors[errors > threshold], sigma))\n",
        "        likelihood_total = likelihood_inliers + likelihood_outliers\n",
        "        if likelihood_total > best_likelihood:\n",
        "            best_model = model\n",
        "            best_likelihood = likelihood_total\n",
        "            best_inliers = inliers\n",
        "\n",
        "    return best_model, best_inliers\n",
        "\n",
        "def draw_keypoint_matches(img1, img2, keypoints1, keypoints2, matches, adaptive_threshold, save_path):\n",
        "    good_matches = [m for m in matches if m.distance <= adaptive_threshold]\n",
        "    img_matches = cv2.drawMatches(img1, keypoints1, img2, keypoints2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
        "    cv2.imwrite(save_path, img_matches)\n",
        "\n",
        "def adjust_brightness(img, alpha=0.0, beta=0.0):\n",
        "    return cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
        "\n",
        "def adjust_contrast(img, alpha=0.0, beta=0.0):\n",
        "    return cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
        "\n",
        "def denoise_image(img, weight=0.1):\n",
        "    return img\n",
        "\n",
        "def preprocess_image(img):\n",
        "    img = adjust_brightness(img, alpha=1.0, beta=0.0)\n",
        "    img = adjust_contrast(img, alpha=1.0, beta=0.0)\n",
        "    img = denoise_image(img, weight=0.0)\n",
        "    return img\n",
        "\n",
        "def open_images(fixed_image_path, moving_image_paths):\n",
        "    fixed_image = cv2.imread(fixed_image_path)\n",
        "    moving_images = [cv2.imread(path) for path in moving_image_paths]\n",
        "    fixed_image = preprocess_image(fixed_image)\n",
        "    moving_images = [preprocess_image(img) for img in moving_images]\n",
        "\n",
        "    return fixed_image, moving_images\n",
        "\n",
        "def features_to_keypoints_and_descriptors(features_np):\n",
        "    h, w = int(np.sqrt(features_np.size)), int(np.sqrt(features_np.size))\n",
        "    img = cv2.resize(features_np, (h, w))\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "    sift = cv2.SIFT_create()\n",
        "    keypoints, descriptors = sift.detectAndCompute(img, None)\n",
        "\n",
        "    return keypoints, descriptors\n",
        "\n",
        "def extract_combined_features(image):\n",
        "    sift = cv2.SIFT_create()\n",
        "    sift_keypoints, sift_descriptors = sift.detectAndCompute(image, None)\n",
        "    return sift_keypoints, sift_descriptors\n",
        "\n",
        "def homography_registration(img1, img2, method=cv2.RANSAC, threshold=5.0, threshold_multiplier=5.0):\n",
        "    keypoints1, descriptors1 = extract_combined_features(img1)\n",
        "    keypoints2, descriptors2 = extract_combined_features(img2)\n",
        "\n",
        "    FLANN_INDEX_KDTREE = 1\n",
        "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
        "    search_params = dict(checks=50)\n",
        "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "    matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
        "    good_matches = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.7 * n.distance:\n",
        "            good_matches.append(m)\n",
        "\n",
        "    matches = sorted(good_matches, key=lambda x: x.distance)\n",
        "    median_distance = np.median([m.distance for m in matches])\n",
        "    adaptive_threshold = median_distance * threshold_multiplier\n",
        "\n",
        "    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
        "    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
        "    data = np.hstack([src_pts.reshape(-1, 2), dst_pts.reshape(-1, 2)])\n",
        "    model, inliers = mlesac(data, HomographyModel, min_samples=4, max_iterations=1000, sigma=1.0, threshold=adaptive_threshold)\n",
        "    H = model.H\n",
        "\n",
        "    print(f\"Number of key points found: {len(matches)}\")\n",
        "    print(f\"Adaptive threshold used: {adaptive_threshold}\")\n",
        "    return H, matches, adaptive_threshold, keypoints1, keypoints2\n",
        "\n",
        "def draw_and_save_keypoints(image, keypoints, save_path, color=(218, 232, 28), thickness=3, radius=4):\n",
        "    image_with_keypoints = image.copy()\n",
        "    for kp in keypoints:\n",
        "        center = (int(kp.pt[0]), int(kp.pt[1]))\n",
        "        cv2.circle(image_with_keypoints, center, radius, color, thickness)\n",
        "    cv2.imwrite(save_path, image_with_keypoints)\n",
        "\n",
        "def keypoints_to_csv(keypoints, descriptors, file_name):\n",
        "    with open(file_name, 'w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['Keypoint ID', 'X Coordinate', 'Y Coordinate', 'Scale', 'Orientation', 'Descriptor Vector'])\n",
        "        for idx, kp in enumerate(keypoints):\n",
        "            descriptor_str = ' '.join(map(str, descriptors[idx]))\n",
        "            writer.writerow([idx, kp.pt[0], kp.pt[1], kp.size, kp.angle, descriptor_str])\n",
        "\n",
        "def save_match_details(matches, keypoints1, keypoints2, file_name):\n",
        "    with open(file_name, 'w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['Match ID', 'Keypoint ID (Fixed)', 'Keypoint ID (Moving)', 'Distance/Similarity Score',\n",
        "                         'Displacement Vector Δx', 'Displacement Vector Δy', 'Scale Difference', 'Orientation Difference'])\n",
        "\n",
        "        for idx, match in enumerate(matches):\n",
        "            kp1 = keypoints1[match.queryIdx]\n",
        "            kp2 = keypoints2[match.trainIdx]\n",
        "\n",
        "            displacement_vector = (kp2.pt[0] - kp1.pt[0], kp2.pt[1] - kp1.pt[1])\n",
        "            scale_difference = kp2.size - kp1.size\n",
        "            orientation_difference = kp2.angle - kp1.angle\n",
        "\n",
        "            writer.writerow([idx, match.queryIdx, match.trainIdx, match.distance,\n",
        "                             displacement_vector[0], displacement_vector[1],\n",
        "                             scale_difference, orientation_difference])\n",
        "\n",
        "def save_outlier_details(matches, keypoints1, keypoints2, adaptive_threshold, file_name):\n",
        "    with open(file_name, 'w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['Outlier ID', 'Keypoint ID (Fixed)', 'Keypoint ID (Moving)', 'Original Match ID'])\n",
        "\n",
        "        outlier_id = 0\n",
        "        for idx, match in enumerate(matches):\n",
        "            if match.distance > adaptive_threshold:\n",
        "                writer.writerow([outlier_id, match.queryIdx, match.trainIdx, idx])\n",
        "                outlier_id += 1\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    fixed_image_path = 'Fixed Image'\n",
        "    moving_image_paths = ['Moving Image']\n",
        "    fixed_image, moving_images = open_images(fixed_image_path, moving_image_paths)\n",
        "    height, width = fixed_image.shape[:2]\n",
        "    threshold_multiplier = 1\n",
        "\n",
        "    for idx, img2 in enumerate(moving_images):\n",
        "        start_time = time.time()\n",
        "        H, matches, adaptive_threshold, keypoints1, keypoints2 = homography_registration(fixed_image, img2, threshold_multiplier=threshold_multiplier)\n",
        "        result = cv2.warpPerspective(img2, H, (width, height), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
        "        end_time = time.time()\n",
        "        inliers = np.sum([1 for m in matches if m.distance <= adaptive_threshold])\n",
        "        Registration_time = end_time - start_time\n",
        "        print(\"Registration_time (s): \", Registration_time)\n",
        "        print(f\"Image {idx + 1}: Number of inliers with adaptive threshold: {inliers}\")\n",
        "        cv2.imwrite(f'Registered Image', result)\n",
        "        fixed_threshold = 20\n",
        "        inliers = np.sum([1 for m in matches if m.distance <= fixed_threshold])\n",
        "\n",
        "        fixed_sift_keypoints, fixed_sift_descriptors = extract_combined_features(fixed_image)\n",
        "        moving_sift_keypoints, moving_sift_descriptors = extract_combined_features(img2)\n",
        "\n",
        "        print(f\"Image {idx + 1}: Number of inliers without adaptive threshold: {inliers}\")\n"
      ],
      "metadata": {
        "id": "PnHLW9MDGy-5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}